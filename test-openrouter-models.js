require('dotenv').config({ path: '.env.local' });

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;

if (!OPENROUTER_API_KEY) {
    console.error('âŒ OPENROUTER_API_KEY is not set');
    process.exit(1);
}

// å¯èƒ½çš„æ¨¡åž‹åç§°å˜ä½“
const possibleModels = [
    'lizpreciatior/lzlv-70b-fp16-hf',  // åŽŸå§‹åç§°
    'lizpreciatior/lzlv-70b',          // ç®€åŒ–ç‰ˆæœ¬
    'lizpreciatior/lzlv-70b-fp16',     // åŽ»æŽ‰ -hf
    'lizpreciatior/lzlv-70b-hf',       // åŽ»æŽ‰ fp16
    'lizpreciatior/lzlv-70b-fp16-hf:free',  // å…è´¹ç‰ˆæœ¬
    'lizpreciatior/lzlv-70b:free',     // å…è´¹ç®€åŒ–ç‰ˆ
    // å…¶ä»–å¯èƒ½çš„æ¨¡åž‹
    'meta-llama/llama-3.1-70b-instruct',
    'meta-llama/llama-3.1-8b-instruct',
    'anthropic/claude-3.5-sonnet',
    'openai/gpt-4o',
];

async function testModel(modelName) {
    try {
        console.log(`\nðŸ§ª Testing: ${modelName}`);
        
        const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${OPENROUTER_API_KEY}`,
                "Content-Type": "application/json",
            },
            body: JSON.stringify({
                model: modelName,
                messages: [
                    { role: "user", content: "Hi" }
                ],
                max_tokens: 10,
            }),
        });

        if (response.ok) {
            const data = await response.json();
            console.log(`âœ… SUCCESS: ${modelName}`);
            console.log(`   Response: ${data.choices[0]?.message?.content || 'No content'}`);
            return { success: true, model: modelName };
        } else {
            const errorText = await response.text();
            console.log(`âŒ FAILED: ${modelName}`);
            console.log(`   Error: ${response.status} ${errorText.substring(0, 200)}`);
            return { success: false, model: modelName, error: errorText };
        }
    } catch (error) {
        console.log(`âŒ ERROR: ${modelName}`);
        console.log(`   ${error.message}`);
        return { success: false, model: modelName, error: error.message };
    }
}

async function listAvailableModels() {
    try {
        console.log('\nðŸ“‹ Fetching available models from OpenRouter...');
        const response = await fetch("https://openrouter.ai/api/v1/models", {
            headers: {
                "Authorization": `Bearer ${OPENROUTER_API_KEY}`,
            },
        });

        if (response.ok) {
            const data = await response.json();
            console.log(`\nâœ… Found ${data.data?.length || 0} models`);
            
            // æœç´¢åŒ…å« lzlv æˆ– lizpreciatior çš„æ¨¡åž‹
            const lzlvModels = data.data?.filter(m => 
                m.id?.toLowerCase().includes('lzlv') || 
                m.id?.toLowerCase().includes('lizpreciatior')
            ) || [];
            
            if (lzlvModels.length > 0) {
                console.log('\nðŸŽ¯ Found lzlv-related models:');
                lzlvModels.forEach(m => {
                    console.log(`   - ${m.id} (${m.name || 'N/A'})`);
                });
            } else {
                console.log('\nâš ï¸  No lzlv models found. Showing first 10 models:');
                data.data?.slice(0, 10).forEach(m => {
                    console.log(`   - ${m.id}`);
                });
            }
            
            return lzlvModels;
        } else {
            console.log(`âŒ Failed to fetch models: ${response.status}`);
            return [];
        }
    } catch (error) {
        console.log(`âŒ Error fetching models: ${error.message}`);
        return [];
    }
}

async function runTests() {
    console.log('ðŸ” Testing OpenRouter Models...\n');
    
    // å…ˆåˆ—å‡ºå¯ç”¨æ¨¡åž‹
    const availableModels = await listAvailableModels();
    
    // å¦‚æžœæœ‰æ‰¾åˆ° lzlv æ¨¡åž‹ï¼Œä¼˜å…ˆæµ‹è¯•å®ƒä»¬
    const modelsToTest = availableModels.length > 0 
        ? availableModels.map(m => m.id).concat(possibleModels)
        : possibleModels;
    
    // åŽ»é‡
    const uniqueModels = [...new Set(modelsToTest)];
    
    console.log(`\nðŸ§ª Testing ${uniqueModels.length} models...`);
    
    const results = [];
    for (const model of uniqueModels) {
        const result = await testModel(model);
        results.push(result);
        // é¿å…è¯·æ±‚è¿‡å¿«
        await new Promise(resolve => setTimeout(resolve, 500));
    }
    
    const successful = results.filter(r => r.success);
    console.log(`\n\nðŸ“Š Results: ${successful.length}/${results.length} models worked`);
    
    if (successful.length > 0) {
        console.log('\nâœ… Working models:');
        successful.forEach(r => console.log(`   - ${r.model}`));
    }
}

runTests().catch(console.error);


